# [論文] アソシエーションルールを用いたアイテム推薦におけるアイテムベースとユーザベースの性能比較

## 概要
アイテムベースとユーザベースの推薦システムを使って、それぞれの性能を評価してみた。  
ユーザベースとは、対象ユーザに最も近い距離のユーザを選び、
そのユーザが評価した内容を対象ユーザも同じように評価するだろうとして推薦する。
  
```
「近いユーザが好きなものを、他のユーザにすすめる」みたいな感じ
```

アイテムベースとは、アイテムが評価された内容から、関連する他のアイテムをすすめる。
```
「アイテム1を好きな人は、アイテム2も好きとする場合が多い」ってことがわかっていたとする。
アイテム1を好きとした人に、アイテム2を進めるって感じ。
```
MovieLensとJesterJokeを用いて実験をした(映画の評価サイト)。  
評価は精度、新規性としてNovelty, Personalizablityを指標として使う。  
MovieLensでは、アイテムベース＞ユーザベースの結果が出た。  
JesterJokeでは、アイテムベース＞ユーザベース(where 評価数が少ない), ユーザベース＞アイテムベース（where 評価数が多い)となった。
未評価割合を比較すると、MovieLens=0.774, JesterJoke=0.01となった。 
Denseなデータのときは、共通して評価したアイテムが増えるため、ユーザベースの評価が上昇したと考えられる。  

本研究では、JesterJokeに対して、途中からアイテムベース→ユーザベースに評価方法を切り替える実験を行った。
評価軸、精度、novelty、personalizabilityがいずれも上昇することを確認した。




## 外部リンク
* [[人工知能学会]アソシエーションルールを用いたアイテム推薦におけるアイテムベースとユーザベースの性能比較](https://kaigi.org/jsai/webprogram/2013/pdf/435.pdf)
